{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "civilian-married",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import *\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-blade",
   "metadata": {},
   "source": [
    "Problem with imbalanced dataset:<br>\n",
    "Most of the Machine Learning algorithms are based on the inherent assumption that the data is balanced, i.e., the data is equally distributed among all of its classes. When training a model on an imbalanced dataset, the learning becomes biased towards the majority classes. With more number of examples available to learn from, the model learns to perform well on the majority classes but due to the lack of enough examples the model fails to learn meaningful patterns that could aid it in learning the minority classes.<br>\n",
    "Loss functions for multi-class classification with imbalanced dataset:<br>\n",
    "Focal Loss<br>\n",
    "Ref1(Research paper): https://arxiv.org/pdf/1708.02002.pdf<br>\n",
    "Ref2: https://youtu.be/Y8_OVwK4ECk<br>\n",
    "Ref3: https://medium.com/gumgum-tech/handling-class-imbalance-by-introducing-sample-weighting-in-the-loss-function-3bdebd8203b4 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ready-jimmy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To understand focal loss we need to first understand what is cross-entropy loss\n",
    "#cross entropy loss\n",
    "def cross_entropy(x,y):\n",
    "    assert(len(x)==len(y))\n",
    "    for e in y:\n",
    "        assert((e==0 or e==1))\n",
    "    for e in x:\n",
    "        assert(e<1 and e>0)\n",
    "    m=len(x)\n",
    "    loss=lambda m,n:-log(m) if n==1 else -log(1-m)\n",
    "    \n",
    "    sigma=0\n",
    "    i=0\n",
    "    for e in x:\n",
    "        sigma+=loss(e,y[i])\n",
    "        i+=1\n",
    "    result=sigma/m\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dietary-harbor",
   "metadata": {},
   "source": [
    "For the above cost function, it can be noticed by plotting graphs that even when probbility is significantly greater than 0.5 there is some non-trivial loss which should be avoided. By using focal loss, having two hyper parameters alpha(for imbalanced data) and gamma(power to which a certain quantity in loss function is raised), we intend to achieve the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "seasonal-february",
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(x,y,gamma=2,alpha=None):\n",
    "    assert(len(x)==len(y))\n",
    "    for e in y:\n",
    "        assert(e==0 or e==1)\n",
    "    for e in x:\n",
    "        assert(e<1 and e>0)\n",
    "    \n",
    "    m=len(x)\n",
    "    if alpha==None or (alpha<0 and alpha>1):\n",
    "        loss=lambda m,n:(-(1-m)**gamma)*log(m) if n==1 else (-(m**gamma)*log(1-m))\n",
    "    else:\n",
    "        loss=lambda m,n:-(alpha*(1-m)**gamma)*log(m) if n==1 else (-(1-alpha)*(m**gamma)*log(1-m))\n",
    "    sigma=0\n",
    "    i=0\n",
    "    for e in x:\n",
    "        sigma+=loss(e,y[i])\n",
    "        i+=1\n",
    "    result=sigma/m\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "accepted-median",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21136524774857138\n",
      "0.008138528362969378\n",
      "0.00605121601439812\n",
      "0.0012076091899881787\n"
     ]
    }
   ],
   "source": [
    "#testing \n",
    "x=[0.2,0.2,0.2,0.2,0.2,0.2,0.9,0.2,0.2,0.2]\n",
    "y=np.round_(x)\n",
    "print(cross_entropy(x,y))\n",
    "print(focal_loss(x,y))\n",
    "print(focal_loss(x,y,2,0.25))\n",
    "print(focal_loss(x,y,3,0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-adolescent",
   "metadata": {},
   "source": [
    "Another way of dealing with imabalanced dataset is by assigning each class a weight based on their number ina sample, so as to increase their effect in cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-motel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weighted loss\n",
    "#there are several ways of evaluating the weights of each class:\n",
    "#Inverse number of samples(INS)\n",
    "#Inverse of square root of number of samples(ISNS) \n",
    "#Effective number of samples(ENS)for this read Ref 3\n",
    "\n",
    "#input for the below function is x(a list of list having softma activations corresponding to each y_i) and expected output y \n",
    "def weighted_loss(x,y,scheme=\"INS\"):\n",
    "    assert(len(x)==len(y))\n",
    "    y_dash=list(set(y))\n",
    "    n=len(y_dash)\n",
    "    weights=[]\n",
    "    freq=[]\n",
    "    for e in y_dash:\n",
    "        freq.append(y.count(e))\n",
    "    for i in freq:\n",
    "        if scheme=\"INS\":\n",
    "            weights.append(1/(freq))\n",
    "        else if scheme=\"ISNS\":\n",
    "            weights.append(1/sqrt(freq))\n",
    "    normalized=weights/max(weights)\n",
    "    \n",
    "    def loss(p,q):\n",
    "        weight=weights[y_dash.index(q)]\n",
    "        max_p=max(p)\n",
    "        if y=p.index(max_p):\n",
    "            return -log(max_p)\n",
    "        else:\n",
    "            return -log(1-max_p)\n",
    "        \n",
    "    sigma=0\n",
    "    i=0\n",
    "    for e in x:\n",
    "        sigma+=loss(e,y[i])\n",
    "        i+=1\n",
    "    \n",
    "    result=sigma/len(y)\n",
    "    \n",
    "    return result\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-colorado",
   "metadata": {},
   "source": [
    "Evaluation metrics for object detection<br>\n",
    "MAP is the most robust metric for evaluating performance of an object detection algorithm. <br>\n",
    "Ref1 for MAP: https://blog.roboflow.com/mean-average-precision/<br>\n",
    "Ref2 for MAP: https://youtu.be/FppOzcDvaDI<br>\n",
    "\n",
    "Before going to MAP, it is required to know, Precision, Recall, F1, IOU(Intersecion over union), AP(Average Precision)<br>\n",
    "Precision=T.P/(T.P.+F.P.)<br>\n",
    "Recall=T.P./(T.P.+F.N.)<br>\n",
    "F1 Score=2*P*R/(P+R)<br>\n",
    "\n",
    "Also, there is something called semantic segmentation whose evaluation metrics are similar to that for object detection.<br>\n",
    "Ref for semantic segmentation:https://youtu.be/uiE56h5LyXc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "opposed-therapist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IOU(Intersecion over union):It is ratio of area of intersection 0f predicted bounding box by a model and ground truth \n",
    "#bounding box to that for union.\n",
    "def IOU(x,y):# input format (bottom left x,bottom left y, width, height)\n",
    "    assert(len(x)==4 and len(y)==4)\n",
    "    relu=lambda x:x if x>0 else 0\n",
    "    \n",
    "    width=min(x[0]+x[2],y[0]+y[2])-max(x[0],y[0])\n",
    "    height=min(x[1]+x[3],y[1]+y[3])-max(x[0],y[0])\n",
    "    \n",
    "    if width<0 or height<0:\n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "        return 1/(((x[2]*x[3]+y[2]*y[3])/width*height)-1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-penetration",
   "metadata": {},
   "source": [
    "IOU is used as a threshold for tagging a bounding box as T.P. or F.P..<br> \n",
    "Precision-recall graph is ploted after the classifying each bounding box as discussed above. Notice the way the graph is plotted is by calculating precision and recall progresively. Watch Ref2 video to clear that.\n",
    "To calculate AP of a particular class, the area under the graph is calculated. Thereafter to get mAP, mean of all the AP's(of all the classes) is calculated. Now.....again mean is taken for various threshold values (say from a to b in steps of c).\n",
    "This is represented as mAP@a:c:b."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-bradford",
   "metadata": {},
   "source": [
    "Batch normalization<br>\n",
    "It is often required to normalize(rescaling the data to be in the inerval [0,1]) the input dataset(if the data is of varied scale) in order to stablize the training of a neural network and for faster convergence. In batch normalization, even the outputs from layers of the neural network are normalized to make sure faster convergence and lesser training time in each step.<br>Precisely, what is done in batch normalization is actually standardization(subtraction by mean and then divided by standard deviation) w.r.t. to samples in batches(and NOT w.r.t. various activations for a single sample).<br>\n",
    "Ref:https://youtu.be/dXB-KQYkzNU <br>\n",
    "<br>\n",
    "Layer normalization<br>\n",
    "The only difference for batch normalization is that the standardiztion tha is carried out after each layer is w.r.t. all the activations corresponding to a single sample input. This is not very useful for inputs as images, but for networks in which inputs are of variable lengths.(eg,RNN(Recurrent Neural Network))<br>\n",
    "Ref for layer normalization :https://youtu.be/eyPZ9Mrhri4<br>\n",
    "Ref for RNN:https://youtu.be/Y2wfIKQyd1I<br>\n",
    "RNN are used for sequential network where the depth of the network depends on length of the input(usually the case with NLP).<br>\n",
    "<br>\n",
    "Activation Functions<br>\n",
    "Activation functions are functions which given a certain output based on the iput to it from a layer in  neural network. Generally, non-linear activation functions are used in neural networks because it can be proved that usig linear activation functions ultimately yields output y as a linear function of inputs and hence the hidden layers do not play much role in expressing complex functions through that neural network.Eg(Tanh, Sigmoid, relu)<br>\n",
    "Ref: https://youtu.be/NkOv_k7r6no<br>\n",
    "<br>\n",
    "\n",
    "Dropout regularization<br>\n",
    "Regularization is in layman's terms ways of reducing chances of over-fitting or under-fitting by a deep learning network. Dropout regularization, in particular, inovloves randomly deactivating neurons for different samples so that a particular feature does not depend on weights connected to a given activation. This way the problem of over-fitting is take care of.  \n",
    "Ref:https://youtu.be/lcI8ukTUEbo<br>\n",
    "<br>\n",
    "\n",
    "Pooling layers<br>\n",
    "Mainly of two types:-<br>\n",
    "Max pooling(most common):Based on the hyperparameters(stride and dimensions of the filter) when convolved over a matrix(say 2-D) outputs the max of all the elements for that convolution. If the number of channels is say n_c, then the output also has the same number of channels and pooling is applied on each channel separately.<br>\n",
    "Average pooling(rare):Outputs average of the elements.<br>\n",
    "Note that there are no parameters to learn. Also usually no padding is used. The main purpose of pooling is (intuitively) get the most weighing feature in that particular part of the matrix. <br>\n",
    "Ref: https://www.coursera.org/learn/convolutional-neural-networks/lecture/hELHk/pooling-layers<br>\n",
    "<br>\n",
    "\n",
    "R-CNN<br>\n",
    "Regions with CNN(R-CNN) is a 2 stage object detection algorithm and has many variants(fast R-CNN and faster R-CNN). Superficially, the first stage involves selective search algorithm, where the algorithm returns a given number of regions(bounding boxes), to feed to AlexNet(an architecture of CNN, the scond stage of the algorithm), after resizing the regions to adjust to the input dimensions of AlexNet. This is not the cutting edge algorithm for object detection, because in 2015, a paper for YOLO algorithm came up and now it is used in most of the areas invloving object detection. The problem with R-CNN is that it is omputationally heavy(though not as heavy as sliding box approach) and very complex. YOLO is faster, and a single stage object detection algorithm. \n",
    "<br>\n",
    "Ref1:https://arxiv.org/pdf/1311.2524.pdf<br>\n",
    "Ref2:https://towardsdatascience.com/understanding-regions-with-cnn-features-r-cnn-ec69c15f8ea7<br>\n",
    "Ref3(selective search):https://learnopencv.com/selective-search-for-object-detection-cpp-python/ <br>\n",
    "Ref4(YOLO algorithm): https://youtu.be/ag3DLKsl2vk<br>\n",
    "Ref5(new versions): https://youtu.be/IfRMV2MY9n0<br>\n",
    "<br>\n",
    "\n",
    "Retina Net<br>\n",
    "\n",
    "RetinaNet=ResNet+Feature Pyramid Net+Focal Loss<br>\n",
    "ResNet was the first one-stage object detection architecture that surpassed two-staged detectors w.r.t. accuracy. Two-stage detectors usually have higher accuracy because of segmentation stage, which significantly reduces the negatives. The second stage involves classification network. Due to this two stages the computation time is more. On the othe hand, in one-stage predictions, image segmentation is not carried out, resulting in lower computational time but less accuracy due to too many negatives(although single negative a not have much effect on learning but too many).\n",
    "Ref: https://youtu.be/infFuZ0BwFQ<br>\n",
    "<br>\n",
    "\n",
    "Bounding box regression<br>\n",
    "For bounding box regression, the y labels of a simple classification network are modified and the parameters of bounding box are added (hence there is increase in dimensionality of the output). \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "ROI Alignment<br>\n",
    "??\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Use of 1-D convolution<br>\n",
    "1-D convolution might seem as trivially multiplying all the elements by some scalar, however that is only true for 2-D input matrices. For 3-D input matrices, 1-D convolution acts like a network within the network, since it takes input of the form 1X1XN_C and outputs a single value(the filter size is of the form 1X1XN_C). This is useful when it is required to reduce the number of channels in a layer.<br>\n",
    "Ref1: https://arxiv.org/pdf/1312.4400.pdf<br>\n",
    "Ref2: https://www.coursera.org/learn/convolutional-neural-networks/lecture/ZTb8x/networks-in-networks-and-1x1-convolutions<br>\n",
    "<br>\n",
    "\n",
    "ResNets/Skip Connections<br>\n",
    "Although it might seem that building deeper layer should not harm the network, however experiments showed that learning identity functions is difficult and the above claim might not hold true. What resNets do is take the input to a layer and add it to the output of next to next layer. Experiments have shown that this makes the deep networks less prone deteoration due to adding more layers.\n",
    "Ref: https://youtu.be/ZILIbUvp5lk<br>\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-marks",
   "metadata": {},
   "outputs": [],
   "source": [
    "#real time object detection\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
